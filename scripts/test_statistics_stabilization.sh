#!/bin/bash

# =============================================================================
# ç»Ÿè®¡é‡ç¨³å®šåŒ–æœºåˆ¶æµ‹è¯•è„šæœ¬
#
# æµ‹è¯•æ–°å®ç°çš„statistics_stabilizationåŠŸèƒ½ï¼ŒéªŒè¯ï¼š
# 1. å‰100æ­¥ä½¿ç”¨éšæœºç­–ç•¥æ”¶é›†ç»Ÿè®¡é‡
# 2. ç»Ÿè®¡é‡ç¨³å®šåå†å¼€å§‹PPOè®­ç»ƒ
# 3. å¯¹æ¯”æœ‰æ— ç¨³å®šåŒ–çš„è®­ç»ƒæ›²çº¿å·®å¼‚
# =============================================================================

set -e

REPO_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
export PYTHONPATH="${REPO_ROOT}"

# é…ç½®å‚æ•°
TEST_ID=$(date +%Y%m%d_%H%M%S)
NUM_REQUESTS=1000
QPS=2
NUM_REPLICAS=4
OUTPUT_DIR="./outputs/runs/statistics_stabilization_test/run_${TEST_ID}"

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "${OUTPUT_DIR}"

echo "ğŸ§ª å¼€å§‹ç»Ÿè®¡é‡ç¨³å®šåŒ–æœºåˆ¶æµ‹è¯• - Test ID: ${TEST_ID}"
echo "ğŸ“‹ æµ‹è¯•é…ç½®:"
echo "   - è¯·æ±‚æ•°é‡: ${NUM_REQUESTS}"
echo "   - QPS: ${QPS}"
echo "   - å‰¯æœ¬æ•°: ${NUM_REPLICAS}"
echo "   - è¾“å‡ºç›®å½•: ${OUTPUT_DIR}"
echo ""

# åŸºç¡€å‘½ä»¤å‚æ•°
BASE_PARAMS="
  --cluster_config_num_replicas ${NUM_REPLICAS}
  --synthetic_request_generator_config_num_requests ${NUM_REQUESTS}
  --interval_generator_config_type poisson
  --poisson_request_interval_generator_config_qps ${QPS}
  --metrics_config_subsamples 200000
"

# =============================================================================
# æµ‹è¯•1: å¯ç”¨ç»Ÿè®¡é‡ç¨³å®šåŒ–çš„PPOè®­ç»ƒ
# =============================================================================
echo "ğŸ“Š [1/2] æµ‹è¯•å¯ç”¨ç»Ÿè®¡é‡ç¨³å®šåŒ–çš„PPOè®­ç»ƒ..."

python -m vidur.main \
  --global_scheduler_config_type ppo_modular \
  ${BASE_PARAMS} \
  --p_p_o_global_scheduler_modular_config_enable_statistics_stabilization \
  --p_p_o_global_scheduler_modular_config_statistics_stabilization_steps 100 \
  --p_p_o_global_scheduler_modular_config_stabilization_policy random \
  --p_p_o_global_scheduler_modular_config_enable_stabilization_logging \
  --p_p_o_global_scheduler_modular_config_max_queue_requests_per_replica 8 \
  --p_p_o_global_scheduler_modular_config_enable_tensorboard \
  --p_p_o_global_scheduler_modular_config_tensorboard_log_dir "${OUTPUT_DIR}/tensorboard_with_stabilization" \
  --no-p_p_o_global_scheduler_modular_config_enable_checkpoints \
  2>&1 | tee "${OUTPUT_DIR}/with_stabilization.log"

if [ $? -eq 0 ]; then
    echo "âœ… å¯ç”¨ç¨³å®šåŒ–çš„æµ‹è¯•å®Œæˆ"
else
    echo "âŒ å¯ç”¨ç¨³å®šåŒ–çš„æµ‹è¯•å¤±è´¥"
fi

# =============================================================================
# æµ‹è¯•2: ç¦ç”¨ç»Ÿè®¡é‡ç¨³å®šåŒ–çš„PPOè®­ç»ƒï¼ˆå¯¹ç…§ç»„ï¼‰
# =============================================================================
echo "ğŸ“Š [2/2] æµ‹è¯•ç¦ç”¨ç»Ÿè®¡é‡ç¨³å®šåŒ–çš„PPOè®­ç»ƒï¼ˆå¯¹ç…§ç»„ï¼‰..."

python -m vidur.main \
  --global_scheduler_config_type ppo_modular \
  ${BASE_PARAMS} \
  --no-p_p_o_global_scheduler_modular_config_enable_statistics_stabilization \
  --p_p_o_global_scheduler_modular_config_max_queue_requests_per_replica 8 \
  --p_p_o_global_scheduler_modular_config_enable_tensorboard \
  --p_p_o_global_scheduler_modular_config_tensorboard_log_dir "${OUTPUT_DIR}/tensorboard_without_stabilization" \
  --no-p_p_o_global_scheduler_modular_config_enable_checkpoints \
  2>&1 | tee "${OUTPUT_DIR}/without_stabilization.log"

if [ $? -eq 0 ]; then
    echo "âœ… ç¦ç”¨ç¨³å®šåŒ–çš„æµ‹è¯•å®Œæˆ"
else
    echo "âŒ ç¦ç”¨ç¨³å®šåŒ–çš„æµ‹è¯•å¤±è´¥"
fi

# =============================================================================
# åˆ†ææµ‹è¯•ç»“æœ
# =============================================================================
echo ""
echo "ğŸ” åˆ†ææµ‹è¯•ç»“æœ..."

# åˆ›å»ºç»“æœåˆ†æè„šæœ¬
cat > "${OUTPUT_DIR}/analyze_stabilization_effects.py" << 'EOF'
#!/usr/bin/env python3
"""
ç»Ÿè®¡é‡ç¨³å®šåŒ–æ•ˆæœåˆ†æè„šæœ¬

å¯¹æ¯”æœ‰æ— ç»Ÿè®¡é‡ç¨³å®šåŒ–çš„è®­ç»ƒè¿‡ç¨‹ï¼Œåˆ†æï¼š
1. å‰100æ­¥çš„åŠ¨ä½œé€‰æ‹©éšæœºæ€§
2. å¥–åŠ±æ›²çº¿çš„ç¨³å®šæ€§
3. æŸå¤±å‡½æ•°çš„æ”¶æ•›é€Ÿåº¦
"""

import re
import sys
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional

def extract_stabilization_logs(log_path: Path) -> Dict:
    """ä»æ—¥å¿—ä¸­æå–ç»Ÿè®¡é‡ç¨³å®šåŒ–ç›¸å…³ä¿¡æ¯"""
    if not log_path.exists():
        return {"error": f"Log file not found: {log_path}"}

    stabilization_logs = []
    ppo_training_start = None

    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–ç¨³å®šåŒ–é˜¶æ®µæ—¥å¿—
        stabilization_pattern = r'\[STATS_STABILIZATION\] step=(\d+)/(\d+) - collecting baseline statistics'
        for match in re.finditer(stabilization_pattern, content):
            step = int(match.group(1))
            total_steps = int(match.group(2))
            stabilization_logs.append((step, total_steps))

        # æ£€æŸ¥æ˜¯å¦å®Œæˆç¨³å®šåŒ–
        completion_pattern = r'\[STATS_STABILIZATION\] Completed! Normalizer statistics collected over (\d+) steps'
        completion_match = re.search(completion_pattern, content)
        if completion_match:
            completed_steps = int(completion_match.group(1))
        else:
            completed_steps = None

        # æ£€æŸ¥PPOè®­ç»ƒå¼€å§‹
        if "Transitioning to PPO training mode" in content:
            ppo_training_start = True

        # æå–æœ€ç»ˆå½’ä¸€åŒ–ç»Ÿè®¡
        stats_pattern = r'\[STATS_STABILIZATION\] Final normalizer stats - mean_magnitude=([\d.]+), std_magnitude=([\d.]+)'
        stats_match = re.search(stats_pattern, content)
        final_stats = None
        if stats_match:
            final_stats = {
                "mean_magnitude": float(stats_match.group(1)),
                "std_magnitude": float(stats_match.group(2))
            }

        return {
            "stabilization_logs": stabilization_logs,
            "completed_steps": completed_steps,
            "ppo_training_started": ppo_training_start,
            "final_normalizer_stats": final_stats,
            "total_stabilization_logs": len(stabilization_logs)
        }

    except Exception as e:
        return {"error": f"Failed to parse log: {e}"}

def extract_training_metrics(log_path: Path) -> Dict:
    """æå–è®­ç»ƒè¿‡ç¨‹çš„å…³é”®æŒ‡æ ‡"""
    if not log_path.exists():
        return {"error": f"Log file not found: {log_path}"}

    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–PPOæ­¥éª¤çš„å¥–åŠ±
        reward_pattern = r'\[PPO:step=(\d+)\].*reward=([-\d.]+)'
        rewards = []
        for match in re.finditer(reward_pattern, content):
            step = int(match.group(1))
            reward = float(match.group(2))
            rewards.append((step, reward))

        # æå–è®­ç»ƒç»Ÿè®¡
        training_pattern = r'\[PPO:train\] .*pg_loss=([-\d.]+).*v_loss=([-\d.]+).*entropy=([-\d.]+)'
        training_stats = []
        for match in re.finditer(training_pattern, content):
            pg_loss = float(match.group(1))
            v_loss = float(match.group(2))
            entropy = float(match.group(3))
            training_stats.append((pg_loss, v_loss, entropy))

        return {
            "rewards": rewards,
            "training_stats": training_stats,
            "total_reward_logs": len(rewards),
            "total_training_logs": len(training_stats)
        }

    except Exception as e:
        return {"error": f"Failed to parse training metrics: {e}"}

def analyze_early_stability(rewards: List[Tuple[int, float]], window_size: int = 50) -> Dict:
    """åˆ†æå‰æœŸå¥–åŠ±çš„ç¨³å®šæ€§"""
    if len(rewards) < window_size:
        return {"error": "Insufficient data for stability analysis"}

    early_rewards = [r[1] for r in rewards[:window_size]]

    return {
        "mean": np.mean(early_rewards),
        "std": np.std(early_rewards),
        "min": np.min(early_rewards),
        "max": np.max(early_rewards),
        "coefficient_of_variation": np.std(early_rewards) / abs(np.mean(early_rewards)) if np.mean(early_rewards) != 0 else float('inf')
    }

def main():
    if len(sys.argv) < 2:
        print("Usage: python analyze_stabilization_effects.py <output_dir>")
        sys.exit(1)

    output_dir = Path(sys.argv[1])

    # åˆ†æä¸¤ä¸ªæ—¥å¿—æ–‡ä»¶
    with_stabilization_log = output_dir / "with_stabilization.log"
    without_stabilization_log = output_dir / "without_stabilization.log"

    print("=" * 80)
    print("ğŸ“Š ç»Ÿè®¡é‡ç¨³å®šåŒ–æ•ˆæœåˆ†ææŠ¥å‘Š")
    print("=" * 80)
    print()

    # åˆ†æå¯ç”¨ç¨³å®šåŒ–çš„æƒ…å†µ
    print("## å¯ç”¨ç»Ÿè®¡é‡ç¨³å®šåŒ–çš„ç»“æœ")
    print("-" * 40)

    with_results = extract_stabilization_logs(with_stabilization_log)
    if "error" in with_results:
        print(f"âŒ é”™è¯¯: {with_results['error']}")
    else:
        print(f"âœ… ç¨³å®šåŒ–é˜¶æ®µæ—¥å¿—æ•°é‡: {with_results['total_stabilization_logs']}")
        print(f"âœ… å®Œæˆç¨³å®šåŒ–æ­¥æ•°: {with_results['completed_steps']}")
        print(f"âœ… PPOè®­ç»ƒå¼€å§‹: {'æ˜¯' if with_results['ppo_training_started'] else 'å¦'}")

        if with_results['final_normalizer_stats']:
            stats = with_results['final_normalizer_stats']
            print(f"ğŸ“ˆ æœ€ç»ˆå½’ä¸€åŒ–ç»Ÿè®¡ - å‡å€¼å¹…åº¦: {stats['mean_magnitude']:.4f}, æ ‡å‡†å·®å¹…åº¦: {stats['std_magnitude']:.4f}")

    print()

    # åˆ†æç¦ç”¨ç¨³å®šåŒ–çš„æƒ…å†µï¼ˆå¯¹ç…§ç»„ï¼‰
    print("## ç¦ç”¨ç»Ÿè®¡é‡ç¨³å®šåŒ–çš„ç»“æœï¼ˆå¯¹ç…§ç»„ï¼‰")
    print("-" * 40)

    without_results = extract_stabilization_logs(without_stabilization_log)
    if "error" in without_results:
        print(f"ğŸ“ é¢„æœŸç»“æœ: æ— ç¨³å®šåŒ–æ—¥å¿—ï¼ˆæ­£å¸¸ï¼‰")
    else:
        print(f"âš ï¸  æ„å¤–å‘ç°ç¨³å®šåŒ–æ—¥å¿—: {without_results['total_stabilization_logs']}")

    print()

    # å¯¹æ¯”è®­ç»ƒæŒ‡æ ‡
    print("## è®­ç»ƒæŒ‡æ ‡å¯¹æ¯”")
    print("-" * 40)

    with_training = extract_training_metrics(with_stabilization_log)
    without_training = extract_training_metrics(without_stabilization_log)

    if "error" not in with_training and "error" not in without_training:
        # åˆ†æå‰æœŸç¨³å®šæ€§
        with_stability = analyze_early_stability(with_training['rewards'])
        without_stability = analyze_early_stability(without_training['rewards'])

        print("### å‰50æ­¥å¥–åŠ±ç¨³å®šæ€§å¯¹æ¯”:")
        if "error" not in with_stability:
            print(f"å¯ç”¨ç¨³å®šåŒ– - å‡å€¼: {with_stability['mean']:.4f}, æ ‡å‡†å·®: {with_stability['std']:.4f}, å˜å¼‚ç³»æ•°: {with_stability['coefficient_of_variation']:.4f}")

        if "error" not in without_stability:
            print(f"ç¦ç”¨ç¨³å®šåŒ– - å‡å€¼: {without_stability['mean']:.4f}, æ ‡å‡†å·®: {without_stability['std']:.4f}, å˜å¼‚ç³»æ•°: {without_stability['coefficient_of_variation']:.4f}")

        # è®¡ç®—æ”¹å–„ç¨‹åº¦
        if "error" not in with_stability and "error" not in without_stability:
            stability_improvement = (without_stability['coefficient_of_variation'] - with_stability['coefficient_of_variation']) / without_stability['coefficient_of_variation'] * 100
            print(f"ğŸ“ˆ ç¨³å®šæ€§æ”¹å–„: {stability_improvement:.1f}% (å˜å¼‚ç³»æ•°é™ä½)")

    print()
    print("## ç»“è®º")
    print("-" * 40)

    if "error" not in with_results and with_results['completed_steps']:
        print("âœ… ç»Ÿè®¡é‡ç¨³å®šåŒ–æœºåˆ¶æˆåŠŸè¿è¡Œ")
        print(f"âœ… æˆåŠŸæ”¶é›†äº† {with_results['completed_steps']} æ­¥çš„åŸºçº¿ç»Ÿè®¡")
        print("âœ… å¹³æ»‘è¿‡æ¸¡åˆ°PPOè®­ç»ƒæ¨¡å¼")
    else:
        print("âŒ ç»Ÿè®¡é‡ç¨³å®šåŒ–æœºåˆ¶å­˜åœ¨é—®é¢˜")

    print()
    print("=" * 80)

if __name__ == "__main__":
    main()
EOF

# è¿è¡Œåˆ†æ
echo "ğŸ“ˆ ç”Ÿæˆåˆ†ææŠ¥å‘Š..."
python3 "${OUTPUT_DIR}/analyze_stabilization_effects.py" "${OUTPUT_DIR}"

echo ""
echo "ğŸ‰ ç»Ÿè®¡é‡ç¨³å®šåŒ–æœºåˆ¶æµ‹è¯•å®Œæˆï¼"
echo "ğŸ“‚ ç»“æœç›®å½•: ${OUTPUT_DIR}"
echo "ğŸ“Š TensorBoardå¯¹æ¯”:"
echo "   - å¯ç”¨ç¨³å®šåŒ–: ${OUTPUT_DIR}/tensorboard_with_stabilization"
echo "   - ç¦ç”¨ç¨³å®šåŒ–: ${OUTPUT_DIR}/tensorboard_without_stabilization"
echo ""
echo "ğŸ”— æŸ¥çœ‹è¯¦ç»†æ—¥å¿—:"
echo "   cat ${OUTPUT_DIR}/with_stabilization.log | grep STATS_STABILIZATION"
echo "   cat ${OUTPUT_DIR}/without_stabilization.log | head -100"