#!/usr/bin/env python3
"""
PPOè®­ç»ƒæŒ‡æ ‡åˆ†æè„šæœ¬

è¯¥è„šæœ¬ä»CSVæ–‡ä»¶ä¸­æå–å¹¶åˆ†æPPOè®­ç»ƒçš„å…³é”®æŒ‡æ ‡ï¼Œ
åŒ…æ‹¬ç­–ç•¥æŸå¤±ã€ä»·å€¼æŸå¤±ã€ç†µç­‰æ ¸å¿ƒè®­ç»ƒä¿¡æ¯ã€‚
"""

import pandas as pd
import argparse
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns


def load_ppo_metrics(csv_path: str) -> pd.DataFrame:
    """
    åŠ è½½å¹¶è¿‡æ»¤PPOè®­ç»ƒæŒ‡æ ‡æ•°æ®

    Args:
        csv_path: CSVæ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«PPOæ›´æ–°æŒ‡æ ‡çš„DataFrame
    """
    print(f"ğŸ“Š åŠ è½½æŒ‡æ ‡æ–‡ä»¶: {csv_path}")

    # åŠ è½½CSVæ–‡ä»¶
    df = pd.read_csv(csv_path)

    print(f"æ€»è®°å½•æ•°: {len(df)}")
    print(f"æ•°æ®ç±»å‹åˆ†å¸ƒ:")
    print(df['data_type'].value_counts())

    # è¿‡æ»¤PPOæ›´æ–°æ•°æ®
    ppo_updates = df[df['data_type'] == 'ppo_update'].copy()
    print(f"\nPPOæ›´æ–°è®°å½•æ•°: {len(ppo_updates)}")

    return ppo_updates


def analyze_ppo_metrics(ppo_df: pd.DataFrame) -> None:
    """
    åˆ†æPPOè®­ç»ƒæŒ‡æ ‡

    Args:
        ppo_df: PPOæ›´æ–°æ•°æ®çš„DataFrame
    """
    print("\n" + "="*60)
    print("PPOè®­ç»ƒæŒ‡æ ‡åˆ†æ")
    print("="*60)

    # å…³é”®æŒ‡æ ‡åˆ—è¡¨
    key_metrics = [
        'pi_loss',      # ç­–ç•¥æŸå¤±
        'vf_loss',      # ä»·å€¼å‡½æ•°æŸå¤±
        'entropy',      # ç­–ç•¥ç†µ
        'approx_kl',    # è¿‘ä¼¼KLæ•£åº¦
        'clipfrac',     # è£å‰ªæ¯”ä¾‹
        'pg_grad_norm', # ç­–ç•¥æ¢¯åº¦èŒƒæ•°
        'explained_var', # è§£é‡Šæ–¹å·®
        'lr'            # å­¦ä¹ ç‡
    ]

    print("\nğŸ“ˆ å…³é”®æŒ‡æ ‡ç»Ÿè®¡:")
    print("-" * 40)

    for metric in key_metrics:
        if metric in ppo_df.columns:
            values = ppo_df[metric].dropna()
            if len(values) > 0:
                print(f"{metric:15s}: å¹³å‡={values.mean():8.6f}, æ ‡å‡†å·®={values.std():8.6f}, "
                      f"æœ€å°={values.min():8.6f}, æœ€å¤§={values.max():8.6f}")
            else:
                print(f"{metric:15s}: æ— æ•°æ®")
        else:
            print(f"{metric:15s}: åˆ—ä¸å­˜åœ¨")

    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    print("\nğŸ” æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
    print("-" * 40)

    for metric in key_metrics:
        if metric in ppo_df.columns:
            non_null_count = ppo_df[metric].count()
            total_count = len(ppo_df)
            completeness = (non_null_count / total_count) * 100 if total_count > 0 else 0
            print(f"{metric:15s}: {non_null_count}/{total_count} ({completeness:5.1f}%)")
        else:
            print(f"{metric:15s}: åˆ—ä¸å­˜åœ¨")


def plot_training_progress(ppo_df: pd.DataFrame, output_dir: str = None) -> None:
    """
    ç»˜åˆ¶è®­ç»ƒè¿›åº¦å›¾è¡¨

    Args:
        ppo_df: PPOæ›´æ–°æ•°æ®çš„DataFrame
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
    """
    if len(ppo_df) == 0:
        print("âš ï¸  æ²¡æœ‰PPOæ›´æ–°æ•°æ®å¯ä¾›ç»˜å›¾")
        return

    print("\nğŸ“Š ç”Ÿæˆè®­ç»ƒè¿›åº¦å›¾è¡¨...")

    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle('PPOè®­ç»ƒæŒ‡æ ‡è¿›åº¦', fontsize=16)

    # æŒ‡æ ‡ç»˜å›¾é…ç½®
    plot_configs = [
        ('pi_loss', 'ç­–ç•¥æŸå¤±', 'red'),
        ('vf_loss', 'ä»·å€¼å‡½æ•°æŸå¤±', 'blue'),
        ('entropy', 'ç­–ç•¥ç†µ', 'green'),
        ('approx_kl', 'è¿‘ä¼¼KLæ•£åº¦', 'orange'),
        ('clipfrac', 'è£å‰ªæ¯”ä¾‹', 'purple'),
        ('explained_var', 'è§£é‡Šæ–¹å·®', 'brown')
    ]

    for i, (metric, title, color) in enumerate(plot_configs):
        row, col = i // 3, i % 3
        ax = axes[row, col]

        if metric in ppo_df.columns and ppo_df[metric].count() > 0:
            values = ppo_df[metric].dropna()
            steps = ppo_df.loc[values.index, 'step']

            ax.plot(steps, values, color=color, linewidth=2)
            ax.set_title(title)
            ax.set_xlabel('è®­ç»ƒæ­¥æ•°')
            ax.set_ylabel(metric)
            ax.grid(True, alpha=0.3)

            # æ·»åŠ è¶‹åŠ¿çº¿
            if len(values) > 1:
                z = np.polyfit(range(len(values)), values, 1)
                p = np.poly1d(z)
                ax.plot(steps, p(range(len(values))), "--", color='gray', alpha=0.8)
        else:
            ax.text(0.5, 0.5, f'æ— {title}æ•°æ®', ha='center', va='center',
                   transform=ax.transAxes, fontsize=12)
            ax.set_title(title)

    plt.tight_layout()

    if output_dir:
        output_path = Path(output_dir) / 'ppo_training_progress.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {output_path}")

    plt.show()


def export_clean_metrics(ppo_df: pd.DataFrame, output_path: str) -> None:
    """
    å¯¼å‡ºæ¸…ç†åçš„PPOæŒ‡æ ‡æ•°æ®

    Args:
        ppo_df: PPOæ›´æ–°æ•°æ®çš„DataFrame
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # é€‰æ‹©å…³é”®åˆ—
    key_columns = [
        'step', 'datetime', 'timestamp',
        'pi_loss', 'vf_loss', 'entropy', 'approx_kl',
        'clipfrac', 'pg_grad_norm', 'explained_var', 'lr',
        'rollout_length', 'buffer_size'
    ]

    # è¿‡æ»¤å­˜åœ¨çš„åˆ—
    available_columns = [col for col in key_columns if col in ppo_df.columns]
    clean_df = ppo_df[available_columns].copy()

    # ä¿å­˜
    clean_df.to_csv(output_path, index=False)
    print(f"ğŸ“ æ¸…ç†åçš„æŒ‡æ ‡å·²å¯¼å‡º: {output_path}")
    print(f"å¯¼å‡ºåˆ—: {', '.join(available_columns)}")


def main():
    parser = argparse.ArgumentParser(description='åˆ†æPPOè®­ç»ƒæŒ‡æ ‡')
    parser.add_argument('csv_path', help='PPOæŒ‡æ ‡CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', '-o', help='è¾“å‡ºç›®å½•ï¼ˆç”¨äºä¿å­˜å›¾è¡¨å’Œæ¸…ç†æ•°æ®ï¼‰')
    parser.add_argument('--plot', action='store_true', help='ç”Ÿæˆè®­ç»ƒè¿›åº¦å›¾è¡¨')
    parser.add_argument('--export-clean', action='store_true', help='å¯¼å‡ºæ¸…ç†åçš„æŒ‡æ ‡æ•°æ®')

    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    csv_path = Path(args.csv_path)
    if not csv_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return 1

    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir) if args.output_dir else csv_path.parent
    output_dir.mkdir(parents=True, exist_ok=True)

    try:
        # åŠ è½½æ•°æ®
        ppo_df = load_ppo_metrics(str(csv_path))

        if len(ppo_df) == 0:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°PPOæ›´æ–°æ•°æ®")
            return 1

        # åˆ†ææŒ‡æ ‡
        analyze_ppo_metrics(ppo_df)

        # ç”Ÿæˆå›¾è¡¨
        if args.plot:
            import numpy as np  # å»¶è¿Ÿå¯¼å…¥
            plot_training_progress(ppo_df, str(output_dir))

        # å¯¼å‡ºæ¸…ç†æ•°æ®
        if args.export_clean:
            clean_path = output_dir / f"ppo_metrics_clean_{csv_path.stem}.csv"
            export_clean_metrics(ppo_df, str(clean_path))

        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        return 0

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())