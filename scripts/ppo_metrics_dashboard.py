#!/usr/bin/env python3
"""
PPOè®­ç»ƒæŒ‡æ ‡ä»ªè¡¨æ¿

å®æ—¶æ˜¾ç¤ºPPOè®­ç»ƒçš„å…³é”®æŒ‡æ ‡ï¼Œæä¾›æ¸…æ™°çš„è®­ç»ƒè¿›åº¦å¯è§†åŒ–ã€‚
æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼å’Œå®æ—¶ç›‘æ§åŠŸèƒ½ã€‚
"""

import pandas as pd
import argparse
import time
from pathlib import Path
from typing import Optional, Dict, Any
import sys


class PPOMetricsDashboard:
    """PPOè®­ç»ƒæŒ‡æ ‡ä»ªè¡¨æ¿"""

    def __init__(self, csv_path: str, refresh_interval: int = 5):
        """
        åˆå§‹åŒ–ä»ªè¡¨æ¿

        Args:
            csv_path: CSVæ–‡ä»¶è·¯å¾„
            refresh_interval: åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰
        """
        self.csv_path = Path(csv_path)
        self.refresh_interval = refresh_interval
        self.last_step = 0

    def load_latest_metrics(self) -> Optional[pd.DataFrame]:
        """
        åŠ è½½æœ€æ–°çš„PPOæŒ‡æ ‡æ•°æ®

        Returns:
            PPOæ›´æ–°æ•°æ®çš„DataFrameï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            if not self.csv_path.exists():
                return None

            df = pd.read_csv(self.csv_path)
            ppo_updates = df[df['data_type'] == 'ppo_update'].copy()

            if len(ppo_updates) > 0:
                ppo_updates = ppo_updates.sort_values('step')

            return ppo_updates

        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return None

    def format_metric(self, value: float, metric_name: str) -> str:
        """
        æ ¼å¼åŒ–æŒ‡æ ‡å€¼

        Args:
            value: æŒ‡æ ‡å€¼
            metric_name: æŒ‡æ ‡åç§°

        Returns:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if pd.isna(value):
            return "N/A"

        # æ ¹æ®æŒ‡æ ‡ç±»å‹ä½¿ç”¨ä¸åŒçš„æ ¼å¼
        if metric_name in ['pi_loss', 'vf_loss']:
            return f"{value:8.6f}"
        elif metric_name in ['entropy', 'approx_kl', 'explained_var']:
            return f"{value:8.4f}"
        elif metric_name in ['clipfrac']:
            return f"{value:8.6f}"
        elif metric_name in ['pg_grad_norm']:
            return f"{value:8.3f}"
        elif metric_name == 'lr':
            return f"{value:.6f}"
        else:
            return f"{value:8.4f}"

    def get_trend_indicator(self, current: float, previous: float) -> str:
        """
        è·å–è¶‹åŠ¿æŒ‡ç¤ºå™¨

        Args:
            current: å½“å‰å€¼
            previous: å‰ä¸€ä¸ªå€¼

        Returns:
            è¶‹åŠ¿æŒ‡ç¤ºç¬¦
        """
        if pd.isna(current) or pd.isna(previous):
            return "â”€"

        diff = current - previous
        if abs(diff) < 1e-8:
            return "â”€"
        elif diff > 0:
            return "â†‘"
        else:
            return "â†“"

    def display_latest_metrics(self, df: pd.DataFrame) -> None:
        """
        æ˜¾ç¤ºæœ€æ–°çš„æŒ‡æ ‡

        Args:
            df: PPOæŒ‡æ ‡æ•°æ®
        """
        if len(df) == 0:
            print("âš ï¸  æ²¡æœ‰PPOè®­ç»ƒæ•°æ®")
            return

        # è·å–æœ€æ–°çš„è®°å½•
        latest = df.iloc[-1]
        previous = df.iloc[-2] if len(df) > 1 else None

        # æ¸…å±
        print("\033[2J\033[H", end="")

        print("=" * 80)
        print(f"ğŸš€ PPOè®­ç»ƒæŒ‡æ ‡ä»ªè¡¨æ¿ - æ­¥éª¤ {int(latest['step'])}")
        print("=" * 80)

        # æ—¶é—´ä¿¡æ¯
        print(f"â° æœ€æ–°æ›´æ–°: {latest['datetime']}")
        print(f"ğŸ“Š æ€»è®­ç»ƒæ­¥æ•°: {int(latest['step'])}")
        print(f"ğŸ“ˆ PPOæ›´æ–°æ¬¡æ•°: {len(df)}")

        print("\n" + "â”€" * 80)
        print("ğŸ“Š æ ¸å¿ƒè®­ç»ƒæŒ‡æ ‡")
        print("â”€" * 80)

        # æŒ‡æ ‡æ˜¾ç¤ºé…ç½®
        metrics_config = [
            ('pi_loss', 'ç­–ç•¥æŸå¤±', 'Lower is better'),
            ('vf_loss', 'ä»·å€¼å‡½æ•°æŸå¤±', 'Lower is better'),
            ('entropy', 'ç­–ç•¥ç†µ', 'Balance needed'),
            ('approx_kl', 'KLæ•£åº¦', 'Low values preferred'),
            ('clipfrac', 'è£å‰ªæ¯”ä¾‹', 'Low values preferred'),
            ('pg_grad_norm', 'æ¢¯åº¦èŒƒæ•°', 'Moderate values'),
            ('explained_var', 'è§£é‡Šæ–¹å·®', 'Higher is better'),
            ('lr', 'å­¦ä¹ ç‡', 'Fixed/scheduled')
        ]

        for metric, chinese_name, description in metrics_config:
            if metric in latest and not pd.isna(latest[metric]):
                current_val = latest[metric]
                trend = self.get_trend_indicator(
                    current_val,
                    previous[metric] if previous is not None and metric in previous else current_val
                )

                formatted_val = self.format_metric(current_val, metric)
                print(f"{chinese_name:12s} â”‚ {formatted_val} {trend} â”‚ {description}")
            else:
                print(f"{chinese_name:12s} â”‚     N/A     â”‚ {description}")

        # è®­ç»ƒçŠ¶æ€è¯„ä¼°
        print("\n" + "â”€" * 80)
        print("ğŸ¯ è®­ç»ƒçŠ¶æ€è¯„ä¼°")
        print("â”€" * 80)

        if len(df) >= 5:
            recent_df = df.tail(5)
            self.assess_training_health(recent_df)
        else:
            print("â³ æ•°æ®ä¸è¶³ï¼Œéœ€è¦æ›´å¤šè®­ç»ƒæ­¥éª¤è¿›è¡Œè¯„ä¼°")

        print("\n" + "â”€" * 80)
        print(f"ğŸ”„ ä¸‹æ¬¡åˆ·æ–°: {self.refresh_interval}ç§’å (Ctrl+C é€€å‡º)")
        print("â”€" * 80)

    def assess_training_health(self, recent_df: pd.DataFrame) -> None:
        """
        è¯„ä¼°è®­ç»ƒå¥åº·çŠ¶æ€

        Args:
            recent_df: æœ€è¿‘çš„è®­ç»ƒæ•°æ®
        """
        assessments = []

        # ç­–ç•¥æŸå¤±è¶‹åŠ¿
        if 'pi_loss' in recent_df.columns:
            pi_losses = recent_df['pi_loss'].dropna()
            if len(pi_losses) >= 3:
                recent_trend = pi_losses.iloc[-3:].diff().mean()
                if recent_trend < -0.001:
                    assessments.append("âœ… ç­–ç•¥æŸå¤±æŒç»­ä¸‹é™")
                elif recent_trend > 0.001:
                    assessments.append("âš ï¸  ç­–ç•¥æŸå¤±ä¸Šå‡ï¼Œéœ€è¦å…³æ³¨")
                else:
                    assessments.append("ğŸ“Š ç­–ç•¥æŸå¤±ç¨³å®š")

        # ç†µå€¼æ£€æŸ¥
        if 'entropy' in recent_df.columns:
            entropies = recent_df['entropy'].dropna()
            if len(entropies) > 0:
                avg_entropy = entropies.mean()
                if avg_entropy > 1.0:
                    assessments.append("ğŸ² ç†µå€¼è¾ƒé«˜ï¼Œæ¢ç´¢å……åˆ†")
                elif avg_entropy > 0.5:
                    assessments.append("âš–ï¸  ç†µå€¼é€‚ä¸­ï¼Œæ¢ç´¢-åˆ©ç”¨å¹³è¡¡")
                else:
                    assessments.append("ğŸ¯ ç†µå€¼è¾ƒä½ï¼Œç­–ç•¥è¶‹äºç¡®å®š")

        # KLæ•£åº¦æ£€æŸ¥
        if 'approx_kl' in recent_df.columns:
            kl_divs = recent_df['approx_kl'].dropna()
            if len(kl_divs) > 0:
                avg_kl = kl_divs.mean()
                if avg_kl > 0.01:
                    assessments.append("âš ï¸  KLæ•£åº¦è¾ƒé«˜ï¼Œç­–ç•¥å˜åŒ–å‰§çƒˆ")
                elif avg_kl > 0.005:
                    assessments.append("ğŸ“ˆ KLæ•£åº¦é€‚ä¸­ï¼Œç­–ç•¥ç¨³æ­¥ä¼˜åŒ–")
                else:
                    assessments.append("ğŸ”’ KLæ•£åº¦å¾ˆä½ï¼Œç­–ç•¥å˜åŒ–ç¼“æ…¢")

        # è§£é‡Šæ–¹å·®æ£€æŸ¥
        if 'explained_var' in recent_df.columns:
            explained_vars = recent_df['explained_var'].dropna()
            if len(explained_vars) > 0:
                avg_ev = explained_vars.mean()
                if avg_ev > 0.5:
                    assessments.append("âœ… ä»·å€¼å‡½æ•°å­¦ä¹ è‰¯å¥½")
                elif avg_ev > 0.0:
                    assessments.append("ğŸ“Š ä»·å€¼å‡½æ•°å­¦ä¹ è¿›å±•ä¸­")
                else:
                    assessments.append("âš ï¸  ä»·å€¼å‡½æ•°å­¦ä¹ å›°éš¾")

        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
        if assessments:
            for assessment in assessments:
                print(f"  {assessment}")
        else:
            print("  ğŸ“Š æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¯„ä¼°")

    def run_dashboard(self, watch_mode: bool = False) -> None:
        """
        è¿è¡Œä»ªè¡¨æ¿

        Args:
            watch_mode: æ˜¯å¦å¯ç”¨ç›‘æ§æ¨¡å¼
        """
        if not watch_mode:
            # å•æ¬¡æ˜¾ç¤ºæ¨¡å¼
            df = self.load_latest_metrics()
            if df is not None:
                self.display_latest_metrics(df)
            else:
                print("âŒ æ— æ³•åŠ è½½æŒ‡æ ‡æ•°æ®")
            return

        # ç›‘æ§æ¨¡å¼
        print(f"ğŸ‘€ å¯åŠ¨PPOè®­ç»ƒç›‘æ§ - æ–‡ä»¶: {self.csv_path}")
        print(f"ğŸ”„ åˆ·æ–°é—´éš”: {self.refresh_interval}ç§’")
        print("æŒ‰ Ctrl+C é€€å‡ºç›‘æ§\n")

        try:
            while True:
                df = self.load_latest_metrics()
                if df is not None and len(df) > 0:
                    current_step = df.iloc[-1]['step']
                    if current_step != self.last_step:
                        self.display_latest_metrics(df)
                        self.last_step = current_step
                    else:
                        # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œåªæ›´æ–°æ—¶é—´
                        print(f"\râ³ ç­‰å¾…æ–°çš„è®­ç»ƒæ•°æ®... {time.strftime('%H:%M:%S')}", end="", flush=True)
                else:
                    print(f"\râŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º... {time.strftime('%H:%M:%S')}", end="", flush=True)

                time.sleep(self.refresh_interval)

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")


def main():
    parser = argparse.ArgumentParser(description='PPOè®­ç»ƒæŒ‡æ ‡ä»ªè¡¨æ¿')
    parser.add_argument('csv_path', help='PPOæŒ‡æ ‡CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--watch', '-w', action='store_true', help='å¯ç”¨å®æ—¶ç›‘æ§æ¨¡å¼')
    parser.add_argument('--interval', '-i', type=int, default=5, help='åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    csv_path = Path(args.csv_path)
    if not args.watch and not csv_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return 1

    # åˆ›å»ºå¹¶è¿è¡Œä»ªè¡¨æ¿
    dashboard = PPOMetricsDashboard(str(csv_path), args.interval)
    dashboard.run_dashboard(args.watch)

    return 0


if __name__ == "__main__":
    exit(main())