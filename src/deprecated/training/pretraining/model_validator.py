#!/usr/bin/env python3
"""
é¢„è®­ç»ƒæ¨¡å‹éªŒè¯æ¨¡å—

æä¾›æ¨¡å‹å…¼å®¹æ€§æ£€æŸ¥ã€æ ¼å¼éªŒè¯ç­‰åŠŸèƒ½ã€‚
"""

import torch
from pathlib import Path
from typing import Dict, Any, Optional, Tuple


class PretrainedModelValidator:
    """é¢„è®­ç»ƒæ¨¡å‹éªŒè¯å™¨"""

    @staticmethod
    def validate_model(model_path: str) -> Tuple[bool, Dict[str, Any]]:
        """
        éªŒè¯é¢„è®­ç»ƒæ¨¡å‹

        Returns:
            (is_valid, validation_info)
        """
        try:
            model_path = Path(model_path)
            if not model_path.exists():
                return False, {"error": "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨"}

            # åŠ è½½æ¨¡å‹
            checkpoint = torch.load(model_path, map_location='cpu')

            # æ£€æŸ¥å¿…è¦çš„é”®
            required_keys = ['model_state_dict', 'model_config']
            missing_keys = [key for key in required_keys if key not in checkpoint]
            if missing_keys:
                return False, {"error": f"ç¼ºå°‘å¿…è¦çš„é”®: {missing_keys}"}

            # æå–é…ç½®ä¿¡æ¯
            config = checkpoint['model_config']
            metadata = checkpoint.get('training_metadata', {})

            validation_info = {
                "valid": True,
                "model_config": config,
                "training_metadata": metadata,
                "file_size": model_path.stat().st_size,
                "file_path": str(model_path),
            }

            return True, validation_info

        except Exception as e:
            return False, {"error": f"æ¨¡å‹éªŒè¯å¤±è´¥: {str(e)}"}

    @staticmethod
    def check_compatibility(model_config: Dict[str, Any], target_config: Dict[str, Any]) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ¨¡å‹é…ç½®å…¼å®¹æ€§

        Args:
            model_config: é¢„è®­ç»ƒæ¨¡å‹çš„é…ç½®
            target_config: ç›®æ ‡è®­ç»ƒçš„é…ç½®

        Returns:
            (is_compatible, message)
        """
        critical_keys = ['state_dim', 'action_dim']

        for key in critical_keys:
            if model_config.get(key) != target_config.get(key):
                return False, f"å…³é”®é…ç½®ä¸åŒ¹é…: {key} (æ¨¡å‹: {model_config.get(key)}, ç›®æ ‡: {target_config.get(key)})"

        # æ£€æŸ¥å…¶ä»–é…ç½®é¡¹ï¼ˆè­¦å‘Šä½†ä¸é˜»æ­¢ï¼‰
        warning_keys = ['hidden_size', 'layer_N', 'gru_layers']
        warnings = []

        for key in warning_keys:
            if model_config.get(key) != target_config.get(key):
                warnings.append(f"{key}: æ¨¡å‹={model_config.get(key)}, ç›®æ ‡={target_config.get(key)}")

        message = "å…¼å®¹" if not warnings else f"å…¼å®¹ä½†æœ‰å·®å¼‚: {'; '.join(warnings)}"
        return True, message

    @staticmethod
    def print_model_info(validation_info: Dict[str, Any]):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        if not validation_info.get("valid", False):
            print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {validation_info.get('error', 'unknown')}")
            return

        config = validation_info["model_config"]
        metadata = validation_info.get("training_metadata", {})

        print("âœ… é¢„è®­ç»ƒæ¨¡å‹éªŒè¯é€šè¿‡")
        print(f"ğŸ“‚ æ–‡ä»¶è·¯å¾„: {validation_info['file_path']}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {validation_info['file_size'] / 1024 / 1024:.2f} MB")
        print(f"ğŸ”§ æ¨¡å‹é…ç½®:")
        print(f"   - çŠ¶æ€ç»´åº¦: {config.get('state_dim', 'unknown')}")
        print(f"   - åŠ¨ä½œç»´åº¦: {config.get('action_dim', 'unknown')}")
        print(f"   - éšè—å±‚å¤§å°: {config.get('hidden_size', 'unknown')}")
        print(f"   - MLPå±‚æ•°: {config.get('layer_N', 'unknown')}")
        print(f"   - GRUå±‚æ•°: {config.get('gru_layers', 'unknown')}")

        if metadata:
            print(f"ğŸ“ˆ è®­ç»ƒä¿¡æ¯:")
            print(f"   - è®­ç»ƒepoch: {metadata.get('epoch', 'unknown')}")
            print(f"   - æœ€ä½³æŸå¤±: {metadata.get('best_loss', 'unknown')}")
            print(f"   - æ¨¡å‹ç±»å‹: {metadata.get('model_type', 'unknown')}")
            print(f"   - ä¿å­˜æ—¶é—´: {metadata.get('save_time', 'unknown')}")


def validate_pretrained_model(model_path: str, target_config: Optional[Dict[str, Any]] = None) -> bool:
    """
    éªŒè¯é¢„è®­ç»ƒæ¨¡å‹çš„ä¾¿æ·å‡½æ•°

    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        target_config: ç›®æ ‡é…ç½®ï¼ˆå¯é€‰ï¼‰

    Returns:
        æ˜¯å¦éªŒè¯é€šè¿‡
    """
    validator = PretrainedModelValidator()

    # åŸºæœ¬éªŒè¯
    is_valid, validation_info = validator.validate_model(model_path)

    if not is_valid:
        validator.print_model_info(validation_info)
        return False

    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    validator.print_model_info(validation_info)

    # å…¼å®¹æ€§æ£€æŸ¥
    if target_config:
        model_config = validation_info["model_config"]
        is_compatible, message = validator.check_compatibility(model_config, target_config)

        if is_compatible:
            print(f"âœ… é…ç½®å…¼å®¹æ€§: {message}")
        else:
            print(f"âŒ é…ç½®å…¼å®¹æ€§: {message}")
            return False

    return True


if __name__ == "__main__":
    import sys

    if len(sys.argv) != 2:
        print("ç”¨æ³•: python -m src.pretraining.model_validator <model_path>")
        sys.exit(1)

    model_path = sys.argv[1]
    success = validate_pretrained_model(model_path)
    sys.exit(0 if success else 1)