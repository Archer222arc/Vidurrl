#!/usr/bin/env python3
"""
ç‹¬ç«‹é¢„è®­ç»ƒæ¨¡å— - æ ¸å¿ƒè®­ç»ƒé€»è¾‘

æŒ‰ç…§é¡¹ç›®è§„èŒƒï¼Œå°†å¤æ‚çš„é¢„è®­ç»ƒé€»è¾‘æ¨¡å—åŒ–åˆ°src/ä¸­ã€‚
è„šæœ¬åªéœ€è°ƒç”¨æ­¤æ¨¡å—çš„æ¥å£ï¼Œä¿æŒç®€æ´ã€‚
"""

import argparse
import json
import pickle
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
repo_root = Path(__file__).resolve().parent.parent.parent.parent.parent
if str(repo_root) not in sys.path:
    sys.path.insert(0, str(repo_root))

from src.core.models.actor_critic import ActorCritic
from src.core.utils.normalizers import RunningNormalizer


class EnhancedDemoDataset(Dataset):
    """å¢å¼ºçš„ç¤ºæ•™æ•°æ®é›†"""

    def __init__(
        self,
        demo_data: List[Dict[str, Any]],
        normalizer: Optional[RunningNormalizer] = None,
        augment_data: bool = True,
        noise_std: float = 0.01
    ):
        self.demo_data = demo_data
        self.normalizer = normalizer
        self.augment_data = augment_data
        self.noise_std = noise_std

        self.states = []
        self.actions = []
        self.weights = []

        self._preprocess_data()

    def _preprocess_data(self):
        """é¢„å¤„ç†æ•°æ®"""
        strategy_counts = {}

        for item in self.demo_data:
            state = np.array(item['state'], dtype=np.float32)
            action = item['action']
            strategy = item.get('strategy', 'unknown')

            if self.normalizer:
                state = self.normalizer.normalize(state)

            self.states.append(state)
            self.actions.append(action)
            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1

        # è®¡ç®—æ ·æœ¬æƒé‡
        total_samples = len(self.demo_data)
        num_strategies = len(strategy_counts)

        for item in self.demo_data:
            strategy = item.get('strategy', 'unknown')
            strategy_weight = total_samples / (num_strategies * strategy_counts[strategy])
            self.weights.append(strategy_weight)

    def __len__(self):
        return len(self.states)

    def __getitem__(self, idx):
        state = self.states[idx].copy()
        action = self.actions[idx]
        weight = self.weights[idx]

        if self.augment_data and self.noise_std > 0:
            noise = np.random.normal(0, self.noise_std, state.shape)
            state = state + noise

        return torch.tensor(state, dtype=torch.float32), action, weight


class StandalonePretrainer:
    """ç‹¬ç«‹é¢„è®­ç»ƒå™¨ - æ ¸å¿ƒè®­ç»ƒé€»è¾‘"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.device = torch.device(config.get('device', 'cpu'))
        self.output_dir = Path(config['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # æ¨¡å‹é…ç½®
        self.model_config = {
            'state_dim': config['state_dim'],
            'action_dim': config['action_dim'],
            'hidden_size': config['hidden_size'],
            'layer_N': config['layer_N'],
            'gru_layers': config['gru_layers'],
        }

        # åˆ›å»ºæ¨¡å‹
        self.actor_critic = ActorCritic(**self.model_config).to(self.device)

        # è®¾ç½®ä¼˜åŒ–å™¨ - ç›´æ¥è®¿é—®ï¼Œç¼ºå¤±å±æ€§ä¼šè‡ªç„¶æŠ¥é”™
        actor_params = []
        if self.actor_critic.enable_decoupled:
            # è§£è€¦æ¶æ„
            actor_params.extend(self.actor_critic.actor_branch.parameters())
            actor_params.extend(self.actor_critic.actor_head.parameters())
        else:
            # è€¦åˆæ¶æ„
            actor_params.extend(self.actor_critic.actor.parameters())

        self.optimizer = torch.optim.AdamW(
            actor_params,
            lr=config.get('learning_rate', 1e-4),
            weight_decay=config.get('weight_decay', 1e-5)
        )

        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.7, patience=10, verbose=True
        )

        # è®­ç»ƒçŠ¶æ€
        self.epoch = 0
        self.best_loss = float('inf')
        self.patience_counter = 0

        # TensorBoard
        self.writer = SummaryWriter(self.output_dir / "tensorboard")

    def train_epoch(self, dataloader: DataLoader) -> Tuple[float, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.actor_critic.train()
        total_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (states, actions, weights) in enumerate(dataloader):
            states = states.to(self.device)
            actions = torch.tensor(actions, dtype=torch.long).to(self.device)
            weights = torch.tensor(weights, dtype=torch.float32).to(self.device)

            # åˆå§‹åŒ–éšè—çŠ¶æ€ - æ­£ç¡®çš„GRUæ ¼å¼: (num_layers, batch_size, hidden_size)
            batch_size = states.shape[0]
            hxs = torch.zeros(self.actor_critic.gru_layers, batch_size, self.actor_critic.hidden_size,
                            device=self.device)
            mask = torch.ones(batch_size, 1, device=self.device)

            # å‰å‘ä¼ æ’­ - è·å–raw logits (ä¿ç•™æ¢¯åº¦)
            action_logits, _ = self.actor_critic.forward_actor_logits(states, hxs, mask)

            # è®¡ç®—æŸå¤±
            loss = F.cross_entropy(action_logits, actions, reduction='none')
            weighted_loss = (loss * weights).mean()

            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            weighted_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.actor_critic.parameters(), max_norm=1.0)
            self.optimizer.step()

            # ç»Ÿè®¡
            total_loss += weighted_loss.item()
            pred = action_logits.argmax(dim=1)
            correct += (pred == actions).sum().item()
            total += actions.size(0)

            if batch_idx % 100 == 0:
                self.writer.add_scalar('Train/Batch_Loss', weighted_loss.item(),
                                     self.epoch * len(dataloader) + batch_idx)

        return total_loss / len(dataloader), correct / total if total > 0 else 0.0

    def validate(self, dataloader: DataLoader) -> Tuple[float, float]:
        """éªŒè¯æ¨¡å‹"""
        self.actor_critic.eval()
        total_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for states, actions, weights in dataloader:
                states = states.to(self.device)
                actions = torch.tensor(actions, dtype=torch.long).to(self.device)
                weights = torch.tensor(weights, dtype=torch.float32).to(self.device)

                batch_size = states.shape[0]
                hxs = torch.zeros(self.actor_critic.gru_layers, batch_size, self.actor_critic.hidden_size,
                                device=self.device)
                mask = torch.ones(batch_size, 1, device=self.device)

                action_logits, _ = self.actor_critic.forward_actor_logits(states, hxs, mask)

                loss = F.cross_entropy(action_logits, actions, reduction='none')
                weighted_loss = (loss * weights).mean()

                total_loss += weighted_loss.item()
                pred = action_logits.argmax(dim=1)
                correct += (pred == actions).sum().item()
                total += actions.size(0)

        return total_loss / len(dataloader), correct / total if total > 0 else 0.0

    def train(self, demo_files: List[str]) -> Dict[str, List[float]]:
        """æ‰§è¡Œè®­ç»ƒ"""
        config = self.config

        # åŠ è½½æ•°æ®
        all_demo_data = []
        for demo_file in demo_files:
            with open(demo_file, 'rb') as f:
                data = pickle.load(f)
                all_demo_data.extend(data['demo_data'])

        # æ•°æ®é›†åˆ†å‰²
        validation_split = config.get('validation_split', 0.2)
        split_idx = int(len(all_demo_data) * (1 - validation_split))
        train_data = all_demo_data[:split_idx]
        val_data = all_demo_data[split_idx:]

        # åˆ›å»ºæ•°æ®é›†
        train_dataset = EnhancedDemoDataset(train_data, augment_data=True)
        val_dataset = EnhancedDemoDataset(val_data, augment_data=False)

        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4)
        val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4)

        # è®­ç»ƒå¾ªç¯
        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'learning_rate': []}
        epochs = config['epochs']
        early_stopping_patience = config.get('early_stopping_patience', 20)

        for epoch in range(epochs):
            self.epoch = epoch
            start_time = time.time()

            # è®­ç»ƒå’ŒéªŒè¯
            train_loss, train_acc = self.train_epoch(train_loader)
            val_loss, val_acc = self.validate(val_loader)

            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step(val_loss)
            current_lr = self.optimizer.param_groups[0]['lr']

            # è®°å½•å†å²
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)
            history['learning_rate'].append(current_lr)

            # TensorBoardè®°å½•
            self.writer.add_scalars('Loss', {'Train': train_loss, 'Val': val_loss}, epoch)
            self.writer.add_scalars('Accuracy', {'Train': train_acc, 'Val': val_acc}, epoch)
            self.writer.add_scalar('Learning_Rate', current_lr, epoch)

            # æ—©åœæ£€æŸ¥
            if val_loss < self.best_loss:
                self.best_loss = val_loss
                self.patience_counter = 0
                self.save_model("best_model.pt", include_training_state=True)
            else:
                self.patience_counter += 1

            # å®šæœŸä¿å­˜
            if (epoch + 1) % config.get('save_interval', 10) == 0:
                self.save_model(f"checkpoint_epoch_{epoch+1}.pt", include_training_state=True)

            # è¾“å‡ºè¿›åº¦
            epoch_time = time.time() - start_time
            print(f"Epoch {epoch+1:3d}/{epochs} | "
                  f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.3f} | "
                  f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.3f} | "
                  f"LR: {current_lr:.2e} | Time: {epoch_time:.1f}s")

            # æ—©åœ
            if self.patience_counter >= early_stopping_patience:
                print(f"æ—©åœè§¦å‘ (patience={early_stopping_patience})")
                break

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.save_model("final_model.pt", include_training_state=False)

        # ä¿å­˜è®­ç»ƒå†å²
        with open(self.output_dir / "training_history.json", 'w') as f:
            json.dump(history, f, indent=2)

        self.writer.close()
        print(f"ç‹¬ç«‹é¢„è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯æŸå¤±: {self.best_loss:.4f}")

        return history

    def save_model(self, filename: str, include_training_state: bool = False):
        """ä¿å­˜æ¨¡å‹"""
        save_path = self.output_dir / filename

        save_dict = {
            'model_state_dict': self.actor_critic.state_dict(),
            'model_config': self.model_config,
            'training_metadata': {
                'epoch': self.epoch,
                'best_loss': self.best_loss,
                'save_time': datetime.now().isoformat(),
                'model_type': 'standalone_pretrained',
                'architecture': 'actor_critic',
            }
        }

        if include_training_state:
            save_dict.update({
                'optimizer_state_dict': self.optimizer.state_dict(),
                'scheduler_state_dict': self.scheduler.state_dict(),
                'patience_counter': self.patience_counter,
            })

        torch.save(save_dict, save_path)
        print(f"æ¨¡å‹å·²ä¿å­˜: {save_path}")

    def load_model(self, model_path: str, load_training_state: bool = False):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(model_path, map_location=self.device)

        self.actor_critic.load_state_dict(checkpoint['model_state_dict'])

        if load_training_state and 'optimizer_state_dict' in checkpoint:
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            self.epoch = checkpoint.get('epoch', 0)
            self.best_loss = checkpoint.get('best_loss', float('inf'))
            self.patience_counter = checkpoint.get('patience_counter', 0)

        print(f"æ¨¡å‹å·²åŠ è½½: {model_path}")


def main():
    parser = argparse.ArgumentParser(description="ç‹¬ç«‹é¢„è®­ç»ƒæ¨¡å—")
    parser.add_argument("--config", type=str, required=True, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--demo-files", nargs='+', help="ç¤ºæ•™æ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨")

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    with open(args.config, 'r') as f:
        config = json.load(f)

    # åˆ›å»ºé¢„è®­ç»ƒå™¨
    pretrainer = StandalonePretrainer(config)

    # è·å–ç¤ºæ•™æ•°æ®æ–‡ä»¶
    demo_files = args.demo_files or []

    # TODO: è¿™é‡Œåº”è¯¥é›†æˆç¤ºæ•™æ•°æ®æ”¶é›†æ¨¡å—
    # æš‚æ—¶éœ€è¦å¤–éƒ¨æä¾›ç¤ºæ•™æ•°æ®æ–‡ä»¶

    if not demo_files:
        print("âŒ é”™è¯¯: æ²¡æœ‰æŒ‡å®šç¤ºæ•™æ•°æ®æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ --demo-files")
        return

    # æ‰§è¡Œè®­ç»ƒ
    history = pretrainer.train(demo_files)

    print("ğŸ‰ ç‹¬ç«‹é¢„è®­ç»ƒå®Œæˆ!")


if __name__ == "__main__":
    main()